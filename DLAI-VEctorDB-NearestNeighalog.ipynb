{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Course - DLAI: Vector DBs](https://learn.deeplearning.ai/courses/vector-databases-embeddings-applications) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 20 data points with 2 dimensions\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(20,2)\n",
    "\n",
    "# Display Embeddings\n",
    "n = range(len(X))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1], label='Embeddings')\n",
    "ax.legend()\n",
    "\n",
    "for i, txt in enumerate(n):\n",
    "    ax.annotate(txt, (X[i,0], X[i,1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Query with data\n",
    "n = range(len(X))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X[:,0], X[:,1])\n",
    "ax.scatter(0.45,0.2, c='red',label='Query')\n",
    "ax.legend()\n",
    "\n",
    "for i, txt in enumerate(n):\n",
    "    ax.annotate(txt, (X[i,0], X[i,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build an index of the training data that allows the model to efficiently find the nearest neighbors for new, unseen data\n",
    "k = 4\n",
    "neigh = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "neigh.fit(X)\n",
    "\n",
    "# Find the k nearest neighbours for a vector\n",
    "neighbours = neigh.kneighbors([[0.45,0.2]], k, return_distance=True)\n",
    "print(neighbours) \n",
    "\n",
    "#The output of the kneighbors() method is a tuple containing:\n",
    "# Distances: The distances to the nearest neighbors (if return_distance=True).\n",
    "# Indices: The indices of the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "neighbours = neigh.kneighbors([[0.45,0.2]], k, return_distance=True)\n",
    "t1 = time.time()\n",
    "\n",
    "query_time = t1-t0\n",
    "print(f\"Runtime: {query_time: .4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration why k-nearest neighbours has huge compute complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_test(count):\n",
    "    # generate random objects\n",
    "    data = np.random.rand(count,2)\n",
    "    \n",
    "    # prepare brute force index\n",
    "    k=4\n",
    "    neigh = NearestNeighbors(n_neighbors=k, algorithm='brute', metric='euclidean')\n",
    "    neigh.fit(data)\n",
    "\n",
    "    # measure time for a brute force query\n",
    "    t0 = time.time()\n",
    "    neighbours = neigh.kneighbors([[0.45,0.2]], k, return_distance=True)\n",
    "    t1 = time.time()\n",
    "\n",
    "    total_time = t1-t0\n",
    "    print (f\"Runtime: {total_time: .4f}\")\n",
    "\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time20k = speed_test(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force examples\n",
    "time200k = speed_test(200_000)\n",
    "time2m = speed_test(2_000_000)\n",
    "time20m = speed_test(20_000_000)\n",
    "time200m = speed_test(200_000_000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute force kNN implemented on `768` dimensional embeddings\n",
    "The algorithm has a time complexity of O(dn), d = dimensions, n is the number of trainigs data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = 1000\n",
    "dimensions = 768\n",
    "\n",
    "embeddings = np.random.randn(documents, dimensions) # 1000 documents, 768-dimensional embeddings\n",
    "embeddings = embeddings / np.sqrt((embeddings**2).sum(1, keepdims=True)) # L2 normalize the rows, as is common\n",
    "\n",
    "query = np.random.randn(768) # the query vector\n",
    "query = query / np.sqrt((query**2).sum()) # normalize query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "t0 = time.time()\n",
    "# Calculate Dot Product between the query and all data items\n",
    "similarities = embeddings.dot(query)\n",
    "# Sort results\n",
    "sorted_ix = np.argsort(-similarities)\n",
    "t1 = time.time()\n",
    "\n",
    "total = t1-t0\n",
    "print(f\"Runtime for dim={dimensions}, documents_n={documents}: {np.round(total,3)} seconds\")\n",
    "\n",
    "print(\"Top 5 results:\")\n",
    "for k in sorted_ix[:5]:\n",
    "    print(f\"Point: {k}, Similarity: {similarities[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_runs = [1_000, 10_000, 100_000, 500_000]\n",
    "\n",
    "for n in n_runs:\n",
    "    embeddings = np.random.randn(n, dimensions) #768-dimensional embeddings\n",
    "    query = np.random.randn(768) # the query vector\n",
    "    \n",
    "    t0 = time.time()\n",
    "    similarities = embeddings.dot(query)\n",
    "    sorted_ix = np.argsort(-similarities)\n",
    "    t1 = time.time()\n",
    "\n",
    "    total = t1-t0\n",
    "    print(f\"Runtime for 1 query with dim={dimensions}, documents_n={n}: {np.round(total,3)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (f\"To run 1,000 queries: {total * 1_000/60 : .2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate nearest neighbours\n",
    "\n",
    "Vector search libraries for ANN\n",
    "* Annoy (Spotify)\n",
    "* FAISS (Meta)\n",
    "* ScaNN (Google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install utils\n",
    "\n",
    "from random import random, randint\n",
    "from math import floor, log\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib as mtplt\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import *\n",
    "\n",
    "vec_num = 40 # Number of vectors (nodes)\n",
    "dim = 2 ## Dimention. Set to be 2. All the graph plots are for dim 2. If changed, then plots should be commented. \n",
    "m_nearest_neighbor = 2 # M Nearest Neigbor used in construction of the Navigable Small World (NSW)\n",
    "\n",
    "vec_pos = np.random.uniform(size=(vec_num, dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Query vector\n",
    "query_vec = [0.5, 0.5]\n",
    "\n",
    "nodes = []\n",
    "nodes.append((\"Q\",{\"pos\": query_vec}))\n",
    "\n",
    "G_query = nx.Graph()\n",
    "G_query.add_nodes_from(nodes)\n",
    "\n",
    "print(\"nodes = \", nodes, flush=True)\n",
    "\n",
    "pos_query=nx.get_node_attributes(G_query,'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force\n",
    "(G_lin, G_best) = nearest_neigbor(vec_pos,query_vec)\n",
    "\n",
    "pos_lin=nx.get_node_attributes(G_lin,'pos')\n",
    "pos_best=nx.get_node_attributes(G_best,'pos')\n",
    "\n",
    "fig, axs = plt.subplots()\n",
    "\n",
    "nx.draw(G_lin, pos_lin, with_labels=True, node_size=150, node_color=[[0.8,0.8,1]], width=0.0, font_size=7, ax = axs)\n",
    "nx.draw(G_query, pos_query, with_labels=True, node_size=200, node_color=[[0.5,0,0]], font_color='white', width=0.5, font_size=7, font_weight='bold', ax = axs)\n",
    "nx.draw(G_best, pos_best, with_labels=True, node_size=200, node_color=[[0.85,0.7,0.2]], width=0.5, font_size=7, font_weight='bold', ax = axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchial naviagable small world (HNSW)\n",
    "Used by most vector databases, has O(log(n)) time complexity. It is a variation of Navigable small world (NSW) algoirthm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNSW construction\n",
    "GraphArray = construct_HNSW(vec_pos,m_nearest_neighbor)\n",
    "\n",
    "for layer_i in range(len(GraphArray)-1,-1,-1):\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    print(\"layer_i = \", layer_i)\n",
    "        \n",
    "    if layer_i>0:\n",
    "        pos_layer_0 = nx.get_node_attributes(GraphArray[0],'pos')\n",
    "        nx.draw(GraphArray[0], pos_layer_0, with_labels=True, node_size=120, node_color=[[0.9,0.9,1]], width=0.0, font_size=6, font_color=(0.65,0.65,0.65), ax = axs)\n",
    "\n",
    "    pos_layer_i = nx.get_node_attributes(GraphArray[layer_i],'pos')\n",
    "    nx.draw(GraphArray[layer_i], pos_layer_i, with_labels=True, node_size=150, node_color=[[0.7,0.7,1]], width=0.5, font_size=7, ax = axs)\n",
    "    nx.draw(G_query, pos_query, with_labels=True, node_size=200, node_color=[[0.8,0,0]], width=0.5, font_size=7, font_weight='bold', ax = axs)\n",
    "    nx.draw(G_best, pos_best, with_labels=True, node_size=200, node_color=[[0.85,0.7,0.2]], width=0.5, font_size=7, font_weight='bold', ax = axs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HNSW search\n",
    "(SearchPathGraphArray, EntryGraphArray) = search_HNSW(GraphArray,G_query)\n",
    "\n",
    "for layer_i in range(len(GraphArray)-1,-1,-1):\n",
    "    fig, axs = plt.subplots()\n",
    "\n",
    "    print(\"layer_i = \", layer_i)\n",
    "    G_path_layer = SearchPathGraphArray[layer_i]\n",
    "    pos_path = nx.get_node_attributes(G_path_layer,'pos')\n",
    "    G_entry = EntryGraphArray[layer_i]\n",
    "    pos_entry = nx.get_node_attributes(G_entry,'pos')\n",
    "\n",
    "    if layer_i>0:\n",
    "            pos_layer_0 = nx.get_node_attributes(GraphArray[0],'pos')\n",
    "            nx.draw(GraphArray[0], pos_layer_0, with_labels=True, node_size=120, node_color=[[0.9,0.9,1]], width=0.0, font_size=6, font_color=(0.65,0.65,0.65), ax = axs)\n",
    "\n",
    "    pos_layer_i = nx.get_node_attributes(GraphArray[layer_i],'pos')\n",
    "    nx.draw(GraphArray[layer_i], pos_layer_i, with_labels=True, node_size=100, node_color=[[0.7,0.7,1]], width=0.5, font_size=6, ax = axs)\n",
    "    nx.draw(G_path_layer, pos_path, with_labels=True, node_size=110, node_color=[[0.8,1,0.8]], width=0.5, font_size=6, ax = axs)\n",
    "    nx.draw(G_query, pos_query, with_labels=True, node_size=80, node_color=[[0.8,0,0]], width=0.5, font_size=7, ax = axs)\n",
    "    nx.draw(G_best, pos_best, with_labels=True, node_size=70, node_color=[[0.85,0.7,0.2]], width=0.5, font_size=7, ax = axs)\n",
    "    nx.draw(G_entry, pos_entry, with_labels=True, node_size=80, node_color=[[0.1,0.9,0.1]], width=0.5, font_size=7, ax = axs)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
