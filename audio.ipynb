{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a0187c",
   "metadata": {},
   "source": [
    "## Zero-Shot Audio Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49adf368",
   "metadata": {},
   "source": [
    "The `librosa` library may need to have [ffmpeg](https://www.ffmpeg.org/download.html) installed. This page on [librosa](https://pypi.org/project/librosa/) provides installation instructions for ffmpeg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641dcda-9522-4dbc-b9b9-388c5a061748",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673a28d3",
   "metadata": {},
   "source": [
    "### Prepare the dataset of audio recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d422f6b-d6ec-4f54-9022-6268c89a071c",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "# This dataset is a collection of different sounds of 5 seconds\n",
    "# dataset = load_dataset(\"ashraq/esc50\",\n",
    "#                       split=\"train[0:10]\")\n",
    "dataset = load_from_disk(\"./models/ashraq/esc50/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa364c-3ef9-4528-aa80-2ee61f96df55",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "audio_sample = dataset[0]\n",
    "audio_sample\n",
    "\n",
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(audio_sample[\"audio\"][\"array\"],\n",
    "             rate=audio_sample[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167ed318",
   "metadata": {},
   "source": [
    "### Build the `audio classification` pipeline using ðŸ¤— Transformers Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5a5820",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b5c027-2990-4687-b560-3a4db3099c3c",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier = pipeline(\n",
    "    task=\"zero-shot-audio-classification\",\n",
    "    model=\"./models/laion/clap-htsat-unfused\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb02a6f0",
   "metadata": {},
   "source": [
    "More info on [laion/clap-htsat-unfused](https://huggingface.co/laion/clap-htsat-unfused)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea87bb3-6500-4558-9fee-a20bc557f753",
   "metadata": {},
   "source": [
    "### Sampling Rate for Transformer Models\n",
    "- How long does 1 second of high resolution audio (192,000 Hz) appear to the Whisper model (which is trained to expect audio files at 16,000 Hz)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97c904ec-2b9a-424b-bf1d-baad182d4b52",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 * 192000) / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370a1cdb-e824-4d93-a846-58e13f6756c5",
   "metadata": {},
   "source": [
    "- The 1 second of high resolution audio appears to the model as if it is 12 seconds of audio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b89285b-c79d-422a-a9cf-f323205277db",
   "metadata": {},
   "source": [
    "- How about 5 seconds of audio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa97b744-6a6a-49b9-ae26-ba0ff259c0d8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(5 * 192000) / 16000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cb81b-79c3-4852-a8d6-e8e38f6a6b9b",
   "metadata": {},
   "source": [
    "- 5 seconds of high resolution audio appears to the model as if it is 60 seconds of audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da863a69-37f0-4719-9914-d49d3b25c445",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "zero_shot_classifier.feature_extractor.sampling_rate\n",
    "audio_sample[\"audio\"][\"sampling_rate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff8ea7e",
   "metadata": {},
   "source": [
    "Set the correct sampling rate for the input and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c53b982",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from datasets import Audio\n",
    "\n",
    "dataset = dataset.cast_column(\n",
    "    \"audio\",\n",
    "     Audio(sampling_rate=48_000))\n",
    "audio_sample = dataset[0]\n",
    "audio_sample\n",
    "\n",
    "candidate_labels = [\"Sound of a dog\",\n",
    "                    \"Sound of vacuum cleaner\"]\n",
    "\n",
    "zero_shot_classifier(audio_sample[\"audio\"][\"array\"],\n",
    "                     candidate_labels=candidate_labels)\n",
    "\n",
    "candidate_labels = [\"Sound of a child crying\",\n",
    "                    \"Sound of vacuum cleaner\",\n",
    "                    \"Sound of a bird singing\",\n",
    "                    \"Sound of an airplane\"]\n",
    "\n",
    "zero_shot_classifier(audio_sample[\"audio\"][\"array\"],\n",
    "                     candidate_labels=candidate_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aac793",
   "metadata": {},
   "source": [
    "### Automatic Speech Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94127c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install -U datasets\n",
    "!pip install soundfile\n",
    "!pip install librosa\n",
    "!pip install gradio\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# laoding speech dataset in streaming mode to minimize memory usage\n",
    "dataset = load_dataset(\"librispeech_asr\",\n",
    "                       split=\"train.clean.100\",\n",
    "                       streaming=True,\n",
    "                       trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c43b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop through the examples\n",
    "example = next(iter(dataset))\n",
    "\n",
    "# Loop with more than one\n",
    "dataset_head = dataset.take(5)\n",
    "list(dataset_head)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb96b99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio as IPythonAudio\n",
    "IPythonAudio(example[\"audio\"][\"array\"],\n",
    "             rate=example[\"audio\"][\"sampling_rate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f003617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "asr = pipeline(task=\"automatic-speech-recognition\", model=\"distil-whisper/distil-small.en\")\n",
    "\n",
    "asr.feature_extractor.sampling_rate\n",
    "example['audio']['sampling_rate']\n",
    "\n",
    "asr(example[\"audio\"][\"array\"])\n",
    "example[\"text\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
