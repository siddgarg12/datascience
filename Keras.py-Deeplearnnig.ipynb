{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning using keras2.0\n",
    "High level framework for building neural networks. Keras is a front end layer written in python, using TensorFlow or Theano backend (University of Montreal open source, older than TF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load training data set from CSV file\n",
    "training_data_df = pd.read_csv(\"sales_data_training.csv\")\n",
    "\n",
    "# Load testing data set from CSV file\n",
    "test_data_df = pd.read_csv(\"sales_data_test.csv\")\n",
    "\n",
    "# Data needs to be scaled to a small range like 0 to 1 for the neural\n",
    "# network to work well.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Scale both the training inputs and outputs\n",
    "scaled_training = scaler.fit_transform(training_data_df)\n",
    "scaled_testing = scaler.transform(test_data_df)\n",
    "\n",
    "# Print out the adjustment that the scaler applied to the total_earnings column of data\n",
    "print(\"Note: total_earnings values were scaled by multiplying by {:.10f} and adding {:.6f}\".format(scaler.scale_[8], scaler.min_[8]))\n",
    "\n",
    "# Create new pandas DataFrame objects from the scaled data\n",
    "scaled_training_df = pd.DataFrame(scaled_training, columns=training_data_df.columns.values)\n",
    "scaled_testing_df = pd.DataFrame(scaled_testing, columns=test_data_df.columns.values)\n",
    "\n",
    "# Save scaled data dataframes to new CSV files\n",
    "scaled_training_df.to_csv(\"sales_data_training_scaled.csv\", index=False)\n",
    "scaled_testing_df.to_csv(\"sales_data_testing_scaled.csv\", index=False)\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "training_data_df = pd.read_csv(\"sales_data_training_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values\n",
    "\n",
    "RUN_NAME = \"run 2 with 5 nodes\"\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=9, activation='relu', name='layer_1'))\n",
    "model.add(Dense(100, activation='relu', name='layer_2'))\n",
    "model.add(Dense(50, activation='relu', name='layer_3'))\n",
    "model.add(Dense(1, activation='linear', name='output_layer'))\n",
    "\n",
    "# What is optimizer\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\")\n",
    "\n",
    "# Create a TensorBoard logger\n",
    "logger = keras.callbacks.TensorBoard(\n",
    "    log_dir='logs',\n",
    "    write_graph=True,\n",
    "    histogram_freq=5\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2,\n",
    "    callbacks=[logger]\n",
    ")\n",
    "\n",
    "# Load the separate test data set\n",
    "test_data_df = pd.read_csv(\"sales_data_test_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"The mean squared error (MSE) for the test data set is: {}\".format(test_error_rate))\n",
    "\n",
    "# Save the model to disk\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved to disk.\")\n",
    "\n",
    "from keras.models import load_model\n",
    "model = load_model('trained_model.h5')\n",
    "\n",
    "# Load the data we make to use to make a prediction\n",
    "X = pd.read_csv(\"proposed_new_product.csv\").values\n",
    "\n",
    "# Make a prediction with the neural network\n",
    "prediction = model.predict(X)\n",
    "\n",
    "# Grab just the first element of the first prediction (since that's the only have one)\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "# Re-scale the data from the 0-to-1 range back to dollars\n",
    "# These constants are from when the data was originally scaled down to the 0-to-1 range\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.0000036968\n",
    "\n",
    "print(\"Earnings Prediction for Proposed Product - ${}\".format(prediction))\n",
    "Densewithkeras.py\n",
    "Displaying Densewithkeras.py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models are trained using ImageNet data \n",
    "* VGG\n",
    "* ResNet50 (Microsoft)\n",
    "* Inception-v3 (Google)\n",
    "* Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code using ResNet50 model for image recognition\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import resnet50\n",
    "\n",
    "# Load Keras' ResNet50 model that was pre-trained against the ImageNet database\n",
    "model = resnet50.ResNet50()\n",
    "\n",
    "# Load the image file, resizing it to 224x224 pixels (required by this model)\n",
    "img = image.load_img(\"bay.jpg\", target_size=(224, 224))\n",
    "\n",
    "# Convert the image to a numpy array\n",
    "x = image.img_to_array(img)\n",
    "\n",
    "# Add a forth dimension since Keras expects a list of images\n",
    "x = np.expand_dims(x, axis=0)\n",
    "\n",
    "# Scale the input image to the range used in the trained network\n",
    "x = resnet50.preprocess_input(x)\n",
    "\n",
    "# Run the image through the deep neural network to make a prediction\n",
    "predictions = model.predict(x)\n",
    "\n",
    "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
    "predicted_classes = resnet50.decode_predictions(predictions, top=9)\n",
    "\n",
    "print(\"This is an image of:\")\n",
    "\n",
    "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
    "    print(\" - {}: {:2f} likelihood\".format(name, likelihood))\n",
    "\n",
    "image_recognition final.py\n",
    "Displaying image_recognition final.py."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
